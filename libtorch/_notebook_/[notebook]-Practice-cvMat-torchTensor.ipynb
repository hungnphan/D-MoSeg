{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afe06d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "// If you want to add include path\n",
    "#pragma cling add_include_path(\"/home/hung/libtorch/include\")\n",
    "#pragma cling add_include_path(\"/home/hung/libtorch/include/torch/csrc/api/include\")\n",
    "\n",
    "// If you want to add library path\n",
    "#pragma cling add_library_path(\"/home/hung/libtorch/lib\")\n",
    "\n",
    "// If you want to load library for CPU (default)\n",
    "#pragma cling load(\"libc10.so\")\n",
    "#pragma cling load(\"libcaffe2_detectron_ops_gpu.so\")\n",
    "#pragma cling load(\"libcaffe2_module_test_dynamic.so\")\n",
    "#pragma cling load(\"libcaffe2_observers.so\")\n",
    "#pragma cling load(\"libfmt.so\")\n",
    "#pragma cling load(\"libfmt.so.7\")\n",
    "#pragma cling load(\"libfmt.so.7.0.3\")\n",
    "#pragma cling load(\"libgomp-75eea7e8.so.1\")\n",
    "#pragma cling load(\"libjitbackend_test.so\")\n",
    "#pragma cling load(\"libprocess_group_agent.so\")\n",
    "#pragma cling load(\"libshm.so\")\n",
    "#pragma cling load(\"libtensorpipe_agent.so\")\n",
    "#pragma cling load(\"libtorch.so\")\n",
    "#pragma cling load(\"libtorchbind_test.so\")\n",
    "#pragma cling load(\"libtorch_cpu.so\")\n",
    "#pragma cling load(\"libtorch_global_deps.so\")\n",
    "\n",
    "// If you use GPU, add more libraries\n",
    "#pragma cling load(\"libc10_cuda.so\")\n",
    "#pragma cling load(\"libcaffe2_nvrtc.so\")\n",
    "#pragma cling load(\"libcudart-1b201d85.so.10.1\")\n",
    "#pragma cling load(\"libnvrtc-5e8a26c9.so.10.1\")\n",
    "#pragma cling load(\"libnvrtc-builtins.so\")\n",
    "#pragma cling load(\"libnvToolsExt-3965bdd0.so.1\")\n",
    "#pragma cling load(\"libtorch_cuda.so\")\n",
    "#pragma cling load(\"libc10d_cuda_test.so\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d4bec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "// We add include path and library path for OpenCV\n",
    "#pragma cling add_include_path(\"/usr/local/include/opencv4\")\n",
    "#pragma cling add_include_path(\"/usr/local/include/opencv4/opencv2\")\n",
    "#pragma cling add_library_path(\"/usr/local/lib\")\n",
    "\n",
    "// We load lib for OpenCV\n",
    "#pragma cling load(\"libopencv_alphamat.so\")\n",
    "#pragma cling load(\"libopencv_alphamat.so.4.5\")\n",
    "#pragma cling load(\"libopencv_alphamat.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_aruco.so\")\n",
    "#pragma cling load(\"libopencv_aruco.so.4.5\")\n",
    "#pragma cling load(\"libopencv_aruco.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_bgsegm.so\")\n",
    "#pragma cling load(\"libopencv_bgsegm.so.4.5\")\n",
    "#pragma cling load(\"libopencv_bgsegm.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_bioinspired.so\")\n",
    "#pragma cling load(\"libopencv_bioinspired.so.4.5\")\n",
    "#pragma cling load(\"libopencv_bioinspired.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_calib3d.so\")\n",
    "#pragma cling load(\"libopencv_calib3d.so.4.5\")\n",
    "#pragma cling load(\"libopencv_calib3d.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_ccalib.so\")\n",
    "#pragma cling load(\"libopencv_ccalib.so.4.5\")\n",
    "#pragma cling load(\"libopencv_ccalib.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_core.so\")\n",
    "#pragma cling load(\"libopencv_core.so.4.5\")\n",
    "#pragma cling load(\"libopencv_core.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_cudaarithm.so\")\n",
    "#pragma cling load(\"libopencv_cudaarithm.so.4.5\")\n",
    "#pragma cling load(\"libopencv_cudaarithm.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_cudabgsegm.so\")\n",
    "#pragma cling load(\"libopencv_cudabgsegm.so.4.5\")\n",
    "#pragma cling load(\"libopencv_cudabgsegm.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_cudafeatures2d.so\")\n",
    "#pragma cling load(\"libopencv_cudafeatures2d.so.4.5\")\n",
    "#pragma cling load(\"libopencv_cudafeatures2d.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_cudafilters.so\")\n",
    "#pragma cling load(\"libopencv_cudafilters.so.4.5\")\n",
    "#pragma cling load(\"libopencv_cudafilters.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_cudaimgproc.so\")\n",
    "#pragma cling load(\"libopencv_cudaimgproc.so.4.5\")\n",
    "#pragma cling load(\"libopencv_cudaimgproc.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_cudalegacy.so\")\n",
    "#pragma cling load(\"libopencv_cudalegacy.so.4.5\")\n",
    "#pragma cling load(\"libopencv_cudalegacy.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_cudaobjdetect.so\")\n",
    "#pragma cling load(\"libopencv_cudaobjdetect.so.4.5\")\n",
    "#pragma cling load(\"libopencv_cudaobjdetect.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_cudaoptflow.so\")\n",
    "#pragma cling load(\"libopencv_cudaoptflow.so.4.5\")\n",
    "#pragma cling load(\"libopencv_cudaoptflow.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_cudastereo.so\")\n",
    "#pragma cling load(\"libopencv_cudastereo.so.4.5\")\n",
    "#pragma cling load(\"libopencv_cudastereo.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_cudawarping.so\")\n",
    "#pragma cling load(\"libopencv_cudawarping.so.4.5\")\n",
    "#pragma cling load(\"libopencv_cudawarping.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_cudev.so\")\n",
    "#pragma cling load(\"libopencv_cudev.so.4.5\")\n",
    "#pragma cling load(\"libopencv_cudev.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_datasets.so\")\n",
    "#pragma cling load(\"libopencv_datasets.so.4.5\")\n",
    "#pragma cling load(\"libopencv_datasets.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_dnn.so\")\n",
    "#pragma cling load(\"libopencv_dnn.so.4.5\")\n",
    "#pragma cling load(\"libopencv_dnn.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_dnn_objdetect.so\")\n",
    "#pragma cling load(\"libopencv_dnn_objdetect.so.4.5\")\n",
    "#pragma cling load(\"libopencv_dnn_objdetect.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_dnn_superres.so\")\n",
    "#pragma cling load(\"libopencv_dnn_superres.so.4.5\")\n",
    "#pragma cling load(\"libopencv_dnn_superres.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_dpm.so\")\n",
    "#pragma cling load(\"libopencv_dpm.so.4.5\")\n",
    "#pragma cling load(\"libopencv_dpm.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_face.so\")\n",
    "#pragma cling load(\"libopencv_face.so.4.5\")\n",
    "#pragma cling load(\"libopencv_face.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_features2d.so\")\n",
    "#pragma cling load(\"libopencv_features2d.so.4.5\")\n",
    "#pragma cling load(\"libopencv_features2d.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_flann.so\")\n",
    "#pragma cling load(\"libopencv_flann.so.4.5\")\n",
    "#pragma cling load(\"libopencv_flann.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_freetype.so\")\n",
    "#pragma cling load(\"libopencv_freetype.so.4.5\")\n",
    "#pragma cling load(\"libopencv_freetype.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_fuzzy.so\")\n",
    "#pragma cling load(\"libopencv_fuzzy.so.4.5\")\n",
    "#pragma cling load(\"libopencv_fuzzy.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_gapi.so\")\n",
    "#pragma cling load(\"libopencv_gapi.so.4.5\")\n",
    "#pragma cling load(\"libopencv_gapi.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_hdf.so\")\n",
    "#pragma cling load(\"libopencv_hdf.so.4.5\")\n",
    "#pragma cling load(\"libopencv_hdf.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_hfs.so\")\n",
    "#pragma cling load(\"libopencv_hfs.so.4.5\")\n",
    "#pragma cling load(\"libopencv_hfs.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_highgui.so\")\n",
    "#pragma cling load(\"libopencv_highgui.so.4.5\")\n",
    "#pragma cling load(\"libopencv_highgui.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_img_hash.so\")\n",
    "#pragma cling load(\"libopencv_img_hash.so.4.5\")\n",
    "#pragma cling load(\"libopencv_img_hash.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_imgcodecs.so\")\n",
    "#pragma cling load(\"libopencv_imgcodecs.so.4.5\")\n",
    "#pragma cling load(\"libopencv_imgcodecs.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_imgproc.so\")\n",
    "#pragma cling load(\"libopencv_imgproc.so.4.5\")\n",
    "#pragma cling load(\"libopencv_imgproc.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_intensity_transform.so\")\n",
    "#pragma cling load(\"libopencv_intensity_transform.so.4.5\")\n",
    "#pragma cling load(\"libopencv_intensity_transform.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_line_descriptor.so\")\n",
    "#pragma cling load(\"libopencv_line_descriptor.so.4.5\")\n",
    "#pragma cling load(\"libopencv_line_descriptor.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_mcc.so\")\n",
    "#pragma cling load(\"libopencv_mcc.so.4.5\")\n",
    "#pragma cling load(\"libopencv_mcc.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_ml.so\")\n",
    "#pragma cling load(\"libopencv_ml.so.4.5\")\n",
    "#pragma cling load(\"libopencv_ml.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_objdetect.so\")\n",
    "#pragma cling load(\"libopencv_objdetect.so.4.5\")\n",
    "#pragma cling load(\"libopencv_objdetect.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_optflow.so\")\n",
    "#pragma cling load(\"libopencv_optflow.so.4.5\")\n",
    "#pragma cling load(\"libopencv_optflow.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_phase_unwrapping.so\")\n",
    "#pragma cling load(\"libopencv_phase_unwrapping.so.4.5\")\n",
    "#pragma cling load(\"libopencv_phase_unwrapping.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_photo.so\")\n",
    "#pragma cling load(\"libopencv_photo.so.4.5\")\n",
    "#pragma cling load(\"libopencv_photo.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_plot.so\")\n",
    "#pragma cling load(\"libopencv_plot.so.4.5\")\n",
    "#pragma cling load(\"libopencv_plot.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_quality.so\")\n",
    "#pragma cling load(\"libopencv_quality.so.4.5\")\n",
    "#pragma cling load(\"libopencv_quality.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_rapid.so\")\n",
    "#pragma cling load(\"libopencv_rapid.so.4.5\")\n",
    "#pragma cling load(\"libopencv_rapid.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_reg.so\")\n",
    "#pragma cling load(\"libopencv_reg.so.4.5\")\n",
    "#pragma cling load(\"libopencv_reg.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_rgbd.so\")\n",
    "#pragma cling load(\"libopencv_rgbd.so.4.5\")\n",
    "#pragma cling load(\"libopencv_rgbd.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_saliency.so\")\n",
    "#pragma cling load(\"libopencv_saliency.so.4.5\")\n",
    "#pragma cling load(\"libopencv_saliency.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_sfm.so\")\n",
    "#pragma cling load(\"libopencv_sfm.so.4.5\")\n",
    "#pragma cling load(\"libopencv_sfm.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_shape.so\")\n",
    "#pragma cling load(\"libopencv_shape.so.4.5\")\n",
    "#pragma cling load(\"libopencv_shape.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_stereo.so\")\n",
    "#pragma cling load(\"libopencv_stereo.so.4.5\")\n",
    "#pragma cling load(\"libopencv_stereo.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_stitching.so\")\n",
    "#pragma cling load(\"libopencv_stitching.so.4.5\")\n",
    "#pragma cling load(\"libopencv_stitching.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_structured_light.so\")\n",
    "#pragma cling load(\"libopencv_structured_light.so.4.5\")\n",
    "#pragma cling load(\"libopencv_structured_light.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_superres.so\")\n",
    "#pragma cling load(\"libopencv_superres.so.4.5\")\n",
    "#pragma cling load(\"libopencv_superres.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_surface_matching.so\")\n",
    "#pragma cling load(\"libopencv_surface_matching.so.4.5\")\n",
    "#pragma cling load(\"libopencv_surface_matching.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_text.so\")\n",
    "#pragma cling load(\"libopencv_text.so.4.5\")\n",
    "#pragma cling load(\"libopencv_text.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_tracking.so\")\n",
    "#pragma cling load(\"libopencv_tracking.so.4.5\")\n",
    "#pragma cling load(\"libopencv_tracking.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_video.so\")\n",
    "#pragma cling load(\"libopencv_video.so.4.5\")\n",
    "#pragma cling load(\"libopencv_video.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_videoio.so\")\n",
    "#pragma cling load(\"libopencv_videoio.so.4.5\")\n",
    "#pragma cling load(\"libopencv_videoio.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_videostab.so\")\n",
    "#pragma cling load(\"libopencv_videostab.so.4.5\")\n",
    "#pragma cling load(\"libopencv_videostab.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_wechat_qrcode.so\")\n",
    "#pragma cling load(\"libopencv_wechat_qrcode.so.4.5\")\n",
    "#pragma cling load(\"libopencv_wechat_qrcode.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_xfeatures2d.so\")\n",
    "#pragma cling load(\"libopencv_xfeatures2d.so.4.5\")\n",
    "#pragma cling load(\"libopencv_xfeatures2d.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_ximgproc.so\")\n",
    "#pragma cling load(\"libopencv_ximgproc.so.4.5\")\n",
    "#pragma cling load(\"libopencv_ximgproc.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_xobjdetect.so\")\n",
    "#pragma cling load(\"libopencv_xobjdetect.so.4.5\")\n",
    "#pragma cling load(\"libopencv_xobjdetect.so.4.5.2\")\n",
    "#pragma cling load(\"libopencv_xphoto.so\")\n",
    "#pragma cling load(\"libopencv_xphoto.so.4.5\")\n",
    "#pragma cling load(\"libopencv_xphoto.so.4.5.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c694d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <torch/torch.h>\n",
    "#include <opencv2/opencv.hpp>\n",
    "\n",
    "#include <iostream>\n",
    "#include <cstdio>\n",
    "#include <cmath>\n",
    "#include <cstring>\n",
    "#include <string>\n",
    "#include <vector>\n",
    "#include <map>\n",
    "#include <utility>\n",
    "#include <sstream>\n",
    "#include <iomanip>\n",
    "#include <tuple>\n",
    "#include <stdint.h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ce8f013",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Config {\n",
    "    bool            use_multi_gpus                  = true;\n",
    "    std::string     sequence_dir                    = \"data/cdnet\";\n",
    "    std::string     foreground_training_data_dir    = \"data/fg200\";\n",
    "    std::string     scenario_name                   = \"badWeather\";\n",
    "    std::string     sequence_name                   = \"skating\";\n",
    "    \n",
    "    int\t\t\t\tkFPS\t\t\t\t\t\t\t= 240;\n",
    "    int\t\t\t\tkMixture\t\t\t\t\t\t= 4;\n",
    "    int\t\t\t\tkPixelBatch\t\t\t\t\t\t= 128;\n",
    "    \n",
    "    float\t\t\tkLearningRate\t\t\t\t\t= 1e-4;\n",
    "    int\t\t\t\tkEpochs\t\t\t\t\t\t\t= 1;\n",
    "    int \t\t\tkSlidingStep\t\t\t\t\t= 2;\n",
    "    \n",
    "    std::string\t\tCKPT_dir\t\t\t\t\t\t= \"training_ckpt\";\n",
    "    std::string\t\tFG_TRAINING_DATA\t\t\t\t= \"data/fg_train_data\";    \n",
    "    std::string\t\tFG_TRAINING_FRAME\t\t\t\t= \"data/fg_train_frame\";    \n",
    "};\n",
    "\n",
    "static Config config;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afb673a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/fg_train_frame/badWeather/skating/000001\n",
      "[540 x 360], 3\n",
      "[540 x 360], 3\n",
      "[540 x 360], 1\n",
      "540, 360\n",
      "540, 360\n",
      "540, 360\n",
      "0, 0\n",
      "[ INFO:0] global /home/hung/Downloads/opencv-4.5.2/modules/core/src/parallel/registry_parallel.impl.hpp (96) ParallelBackendRegistry core(parallel): Enabled backends(2, sorted by priority): TBB(1000); OPENMP(990)\n",
      "[ INFO:0] global /home/hung/Downloads/opencv-4.5.2/modules/core/include/opencv2/core/parallel/backend/parallel_for.tbb.hpp (54) ParallelForBackend Initializing TBB parallel backend: TBB_INTERFACE_VERSION=9107\n",
      "[ INFO:0] global /home/hung/Downloads/opencv-4.5.2/modules/core/src/parallel/parallel.cpp (77) createParallelForAPI core(parallel): using backend: TBB (priority=1000)\n"
     ]
    }
   ],
   "source": [
    "// Convert int to string with leading zeros\n",
    "int index_int = 1;\n",
    "std::stringstream ss;\n",
    "ss << std::setw(06) << std::setfill('0') << index_int;\n",
    "std::string index_str = ss.str();\n",
    "\n",
    "// Path to frame data\n",
    "std::string path_to_data = config.FG_TRAINING_FRAME + \"/\" \n",
    "    + config.scenario_name + \"/\" \n",
    "    + config.sequence_name + \"/\"\n",
    "    + index_str;\n",
    "\n",
    "std::cout << path_to_data << std::endl;\n",
    "\n",
    "// Read in, bg, fg images from opencv\n",
    "cv::Mat in_img = cv::imread(path_to_data + \"_in.png\", cv::IMREAD_COLOR);\n",
    "cv::Mat bg_img = cv::imread(path_to_data + \"_bg.png\", cv::IMREAD_COLOR);\n",
    "cv::Mat fg_img = cv::imread(path_to_data + \"_fg.png\", cv::IMREAD_GRAYSCALE);\n",
    "\n",
    "////////////////////////////////////////////\n",
    "// DEBUG: print to check size\n",
    "std::cout << in_img.size() << \", \" << in_img.channels() << std::endl;\n",
    "std::cout << bg_img.size() << \", \" << bg_img.channels() << std::endl;\n",
    "std::cout << fg_img.size() << \", \" << fg_img.channels() << std::endl;\n",
    "\n",
    "std::cout << in_img.cols << \", \" << in_img.rows << \"\\n\";\n",
    "std::cout << bg_img.cols << \", \" << bg_img.rows << \"\\n\";\n",
    "std::cout << fg_img.cols << \", \" << fg_img.rows << \"\\n\";\n",
    "\n",
    "std::cout << fg_img.type() << \", \" << CV_8U << std::endl;\n",
    "\n",
    "cv::imshow(\"in_img\", in_img);\n",
    "cv::imshow(\"bg_img\", bg_img);\n",
    "cv::imshow(\"fg_img\", fg_img);\n",
    "\n",
    "cv::waitKey(0);\n",
    "cv::destroyAllWindows();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0195ace6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[540, 360, 3], 3\n",
      "[540, 360, 3], 3\n",
      "[540, 360], 2\n"
     ]
    }
   ],
   "source": [
    "// Convert cv::mat (8U) to torch::Tensor (8U) [H, W, C]\n",
    "torch::Tensor cvt_cvMat_to_torchTensor(cv::Mat& mat){\n",
    "    torch::Tensor tsr;\n",
    "    // BGR image\n",
    "    if(mat.channels() == 3){    \n",
    "        tsr = torch::zeros({mat.cols, mat.rows, mat.channels()},\n",
    "                                         torch::TensorOptions(torch::kUInt8) );\n",
    "        memcpy(tsr.data_ptr(), mat.data, tsr.numel() * sizeof(unsigned char));    \n",
    "    }\n",
    "    // Grayscale image\n",
    "    else if(mat.channels() == 1){   \n",
    "        tsr = torch::zeros({mat.cols, mat.rows},\n",
    "                                         torch::TensorOptions(torch::kUInt8) );\n",
    "        memcpy(tsr.data_ptr(), mat.data, tsr.numel() * sizeof(unsigned char));\n",
    "    }\n",
    "    return tsr;\n",
    "}\n",
    "\n",
    "auto in_tsr = cvt_cvMat_to_torchTensor(in_img);\n",
    "auto bg_tsr = cvt_cvMat_to_torchTensor(bg_img);\n",
    "auto fg_tsr = cvt_cvMat_to_torchTensor(fg_img);\n",
    "\n",
    "std::cout << in_tsr.sizes() << \", \" << in_tsr.dim() << std::endl;\n",
    "std::cout << bg_tsr.sizes() << \", \" << bg_tsr.dim() << std::endl;\n",
    "std::cout << fg_tsr.sizes() << \", \" << fg_tsr.dim() << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e5ab1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[540, 360, 3]\n",
      "[540, 360, 3]\n",
      "[540, 360]\n",
      "[540 x 360], 3\n",
      "[540 x 360], 3\n",
      "[540 x 360], 1\n"
     ]
    }
   ],
   "source": [
    "cv::Mat cvt_torchTensor_to_cvMat(torch::Tensor& tsr){\n",
    "    cv::Mat mat;\n",
    "    // BGR image\n",
    "    if(tsr.dim() == 3)        \n",
    "        mat = cv::Mat(tsr.size(1), tsr.size(0), CV_8UC3);\n",
    "    // Grayscale image\n",
    "    else if(tsr.dim() == 2)\n",
    "        mat = cv::Mat(tsr.size(1), tsr.size(0), CV_8U);\n",
    "        \n",
    "    torch::Tensor flatten_tsr = tsr.contiguous();\n",
    "    std::memcpy(mat.data, (uint8_t*) flatten_tsr.data_ptr(), sizeof(unsigned char) * tsr.numel());\n",
    "    return mat;\n",
    "}\n",
    "\n",
    "auto in_mat = cvt_torchTensor_to_cvMat(in_tsr);\n",
    "auto bg_mat = cvt_torchTensor_to_cvMat(bg_tsr);\n",
    "auto fg_mat = cvt_torchTensor_to_cvMat(fg_tsr);\n",
    "\n",
    "std::cout << in_tsr.sizes() << \"\\n\";\n",
    "std::cout << bg_tsr.sizes() << \"\\n\";\n",
    "std::cout << fg_tsr.sizes() << \"\\n\";\n",
    "\n",
    "std::cout << in_mat.size() << \", \" << in_mat.channels() << std::endl;\n",
    "std::cout << bg_mat.size() << \", \" << bg_mat.channels() << std::endl;    \n",
    "std::cout << fg_mat.size() << \", \" << fg_mat.channels() << std::endl;    \n",
    "\n",
    "cv::imshow(\"in_img\", in_mat);\n",
    "cv::imshow(\"bg_img\", bg_mat);\n",
    "cv::imshow(\"fg_img\", fg_mat);\n",
    "\n",
    "cv::waitKey(0);\n",
    "cv::destroyAllWindows();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7129091c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[540, 360, 3]\n",
      "[540, 360, 3]\n",
      "[540, 360]\n",
      "[540, 360, 1]\n",
      "[540, 360, 7]\n"
     ]
    }
   ],
   "source": [
    "in_tsr = cvt_cvMat_to_torchTensor(in_img);\n",
    "bg_tsr = cvt_cvMat_to_torchTensor(bg_img);\n",
    "fg_tsr = cvt_cvMat_to_torchTensor(fg_img);\n",
    "\n",
    "std::cout << in_tsr.sizes() << std::endl;\n",
    "std::cout << bg_tsr.sizes() << std::endl;\n",
    "std::cout << fg_tsr.sizes() << std::endl;\n",
    "\n",
    "fg_tsr = fg_tsr.unsqueeze(-1);\n",
    "std::cout << fg_tsr.sizes() << std::endl;\n",
    "\n",
    "torch::Tensor tsr = torch::cat({in_tsr,bg_tsr,fg_tsr}, -1);\n",
    "std::cout << tsr.sizes() << std::endl;\n",
    "\n",
    "// auto a = in_tsr.permute({2,0,1});\n",
    "// auto b = bg_tsr.permute({2,0,1});\n",
    "// auto c = fg_tsr.permute({2,0,1});\n",
    "\n",
    "// std::cout << a.sizes() << \"\\n\";\n",
    "// std::cout << b.sizes() << \"\\n\";\n",
    "// std::cout << c.sizes() << \"\\n\";\n",
    "\n",
    "// torch::Tensor tsr = torch::cat({a,b,c}, 0);\n",
    "// std::cout << tsr.sizes() << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69ac4c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[540, 360, 7]\n",
      "[540, 360, 3]\n",
      "unsigned char\n"
     ]
    }
   ],
   "source": [
    "std::cout << tsr.sizes() << std::endl;\n",
    "\n",
    "auto slicing_tsr = tsr.index({ torch::indexing::Ellipsis, torch::indexing::Slice(0,3) });\n",
    "\n",
    "std::cout << slicing_tsr.sizes() << std::endl;\n",
    "\n",
    "std::cout << slicing_tsr.dtype() << std::endl;\n",
    "\n",
    "cv::Mat slicing_mat = cvt_torchTensor_to_cvMat(slicing_tsr);\n",
    "\n",
    "cv::imshow(\"slicing_mat\", slicing_mat);\n",
    "\n",
    "cv::waitKey(0);\n",
    "cv::destroyAllWindows();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e05e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++14",
   "language": "C++14",
   "name": "xcpp14"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
